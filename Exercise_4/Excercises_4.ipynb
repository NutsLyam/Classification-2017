{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Разработка классификатора новостей\n",
    "\n",
    "**Нужно:**\n",
    "* выбрать какой-либо новостной ресурс, где к новостям привязаны категории или метки (например http://lenta.ru, http://fontanka.ru, http://gazeta.ru)\n",
    "* загрузить новости по некоторому набору (5-10) категорий за пару лет\n",
    "* обучить классификатор на эти новостях\n",
    "* продемонстрировать его работу, разработав простеший web-интерфейс (вариант - telegram-бот), куда пользователь вводит текст новости и на выходе получает наиболее вероятную категорию. В качестве фреймворка проще всего взять [Flask](http://flask.pocoo.org) (см. примеры) ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import lxml.html\n",
    "import lxml.etree\n",
    "import requests\n",
    "import sqlite3\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "import pymorphy2\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(\"news_base.db\") \n",
    "cursor = conn.cursor()\n",
    " \n",
    "#Создание таблицы\n",
    "#cursor.execute(\"\"\"CREATE TABLE News\n",
    "#                 ( category text, date text, title text, article text)\n",
    " #            \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nuts\\Anaconda3\\lib\\site-packages\\urllib3\\connectionpool.py:858: InsecureRequestWarning: Unverified HTTPS request is being made. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#ssl-warnings\n",
      "  InsecureRequestWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "path = 'http://m.lenta.ru'\n",
    "response= requests.get(path, verify=False)\n",
    "response.status_code\n",
    "\n",
    "\n",
    "tree = lxml.html.fromstring(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#даты \n",
    "month_31 = ['01', '03','05','07','08','10','12']#не забыть вернуть январь\n",
    "month_30 = ['04','06','09','11']\n",
    "month_29 = ['02']\n",
    "\n",
    "day_31=[]\n",
    "day_30= []\n",
    "day_10 = ['01','02','03','04','05','06','07','08','09']\n",
    "\n",
    "day_29= []\n",
    "for k in range(10,31,1):\n",
    "    str_k = str(k)\n",
    "    day_30.append(str_k)\n",
    "    \n",
    "day_30 = day_10 + day_30 \n",
    "\n",
    "for k in range(10,32,1):\n",
    "    str_k = str(k)   \n",
    "    day_31.append(str_k)\n",
    "    \n",
    "    \n",
    "day_31 = day_10 + day_31 \n",
    "\n",
    "for k in range(10,30,1):\n",
    "    str_k = str(k)   \n",
    "    day_29.append(str_k)\n",
    "day_29 = day_10 + day_29\n",
    "    \n",
    "\n",
    "    \n",
    "date=[]\n",
    "\n",
    "for year in range(2016,2017,1):\n",
    "    \n",
    "    for month in month_31:\n",
    "        for day in day_31:\n",
    "            d = '/%d/%s/%s'%(year,month,day)\n",
    "            date.append(d)\n",
    "   \n",
    "    for month in month_30:\n",
    "        for day in day_30:\n",
    "            d = '/%d/%s/%s'%(year,month,day)\n",
    "            date.append(d)\n",
    "    \n",
    "    for month in month_29:\n",
    "        for day in day_29:\n",
    "            d = '/%d/%s/%s'%(year,month,day)\n",
    "            date.append(d)\n",
    "            \n",
    "    \n",
    " \n",
    "            \n",
    "links = []        \n",
    "for d in date :        \n",
    "    links.append(path + d)\n",
    "\n",
    "#по датам\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = pymorphy2.MorphAnalyzer()  \n",
    "for link in tqdm_notebook(links):\n",
    "\n",
    "        response= requests.get(link, verify=False)\n",
    "        tree = lxml.html.fromstring(response.text)\n",
    "         #статьи\n",
    "        #day_links = tree.xpath('//div[@class=\"item news b-tabloid__topic_news\"]/div[@class = \"titles\"]//a/@href')\n",
    "        i = -1\n",
    "        for que in tree.xpath('//div[@class=\"item news b-tabloid__topic_news\"]/div[@class = \"titles\"]/h3'):\n",
    "            i=i+1\n",
    "            quest = que.xpath('a/@href')\n",
    "            \n",
    "            way = path + quest.pop()\n",
    "            resp= requests.get(way, verify=False)\n",
    "            tree_day = lxml.html.fromstring(resp.text)\n",
    "            category = tree_day.xpath('//div[@class=\"b-subheader__title js-nav-opener\"]/text()')\n",
    "            art = str(tree_day.xpath('//div[@class=\"b-topic__body\"]//p//text()'))\n",
    "            \n",
    "            article = analyzer.normal_forms(art)\n",
    "            #print(article[0])\n",
    "            #print(category)\n",
    "            title = tree_day.xpath('//h1[@class=\"b-topic__title\"]/text()')\n",
    "            date = tree_day.xpath('//div[@class=\"b-topic__date\"]/text()')\n",
    "            cursor.execute(\"INSERT INTO News VALUES (?,?,?,?)\", (category[0], date[0], title[0], article[0]))\n",
    "            conn.commit()\n",
    "            \n",
    "       \n",
    "            \n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(37818,)]\n"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT count(*) FROM News\"\n",
    "cursor.execute(sql)\n",
    "print(cursor.fetchall())\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(2541,)]\n"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT count(*) FROM News where category = ? \"\n",
    "cursor.execute(sql,['Культура'])\n",
    "print( cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "sql = \"Delete  FROM News where category = ? \"\n",
    "cursor.execute(sql,['Путешествия'])\n",
    "conn.commit()\n",
    "print( cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Спорт',), ('Интернет и СМИ',), ('Мир',), ('Наука и техника',), ('Россия',), ('Силовые структуры',), ('Культура',), ('Бывший СССР',), ('Финансы',)]\n"
     ]
    }
   ],
   "source": [
    "sql = \"SELECT DISTINCT category FROM News \"\n",
    "#sql = \"Select date from news\"\n",
    "cursor.execute(sql)\n",
    "print( cursor.fetchall())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    " \n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87934693877551018"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = sqlite3.connect(\"news_base.db\") \n",
    "cursor = conn.cursor()\n",
    "\n",
    "\n",
    "sql = \"Select  category FROM News \"\n",
    "cursor.execute(sql)\n",
    "targets = [t[0] for t in cursor.fetchall()[:35000]] \n",
    "    \n",
    "    \n",
    "sql = \"Select article FROM News \"\n",
    "cursor.execute(sql)\n",
    "text = [t[0] for t in cursor.fetchall()[:35000]]\n",
    "     \n",
    "    \n",
    "count_vect = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    " \n",
    "X = count_vect.fit_transform(text)\n",
    "X = tfidf_transformer.fit_transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, targets, test_size=0.35, random_state=0)\n",
    "clf = LogisticRegression(C=100).fit(X_train, y_train)\n",
    "#clf = svm.SVC(kernel='linear', C=100).fit(X_train, y_train)\n",
    "#clf.score(X_test, y_test) \n",
    "\n",
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "with open('count_vect.pkl', 'wb') as f:\n",
    "    pickle.dump(count_vect,f)\n",
    "\n",
    "\n",
    "with open('clf.pkl', 'wb') as f: \n",
    "    pickle.dump(clf, f) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('clf.pkl', 'rb') as f: \n",
    "    clf = pickle.load(f) \n",
    "    \n",
    "with open('count_vect.pkl', 'rb') as f: \n",
    "    count_vect = pickle.load(f) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Финансы'"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "que = \"деньги\"\n",
    "predicted = clf.predict(count_vect.transform([que]).toarray())\n",
    "predicted[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
